---
layout: article
title: 图对比学习&数据增强
date: 2021-01-05 00:10:00 +0800
tags: [Graph, Data Augmentation, Graph Contrastive Learning]
categories: blog
pageview: true
key: Graph-Contrastive-Learning-with-data-Augmentations
---

------

本质上来说，对比学习通过最大化不同视角间的一致性来学习表征，学习到的表征对数据增强方案引入的扰动具有鲁棒性（不变性）。换句话说，不同数据增强方案引入不同的扰动，生成不同视角的样本，对比学习能够通过最大化不同视角间的一致性，学习到不变性的特征表示。

数据增强是对比学习的前提。

------

### Paper 1

- Paper: **Deep Graph InfoMax** (ICLR2019)
- Code: [https://github.com/PetarV-/DGI](https://github.com/PetarV-/DGI)

#### Model

![image-20210106211638287](https://raw.githubusercontent.com/jjzhou012/image/master/blogImg20210106211638.png)

1. 利用一个“腐蚀函数”，来对网络结构进行修改，从而获得负样本。

2. **Patch representations** 

   GCN通过邻域聚合学习节点表征，故又称patch rep; 采用GCN编码器学习节点向量；

   1. 学习输入图的节点表示
   2. 学习负样本的节点表示

3. **Global Summaries**

   全局特征通过Readout函数获得。论文尝试了几种readout函数，发现效果最好且最简单的方法就是对所有patch rep 取平均；

4. 对目标函数进行学习，更新参数

![image-20210106211605817](https://raw.githubusercontent.com/jjzhou012/image/master/blogImg20210106211605.png)

> 通过计算节点表示和图表示之间的相似度，应该是希望加强局部信息（节点表示）和全局信息（图表示）的一致性。 

------

### Paper 2

- Paper: **Graph Contrastive Learning with Augmentations** (NeurIPS 2020) 
- Code: [https://github.com/Shen-Lab/GraphCL](https://github.com/Shen-Lab/GraphCL)

#### DA

![image-20201222205415864](https://raw.githubusercontent.com/jjzhou012/image/master/blogImg20201222205416.png)

- 节点删除（Node dropping）: 随机从图中删除一部分节点来扰动图的完整性，每个节点的删除概率遵循默认的独立同均匀分布(或任何其他分布)，约束的先验为删除的节点不影响整个图的语义信息。
- 边扰动（Edge perturbation）: 随机从图中增删一部分边来扰动图的邻接信息，每条边的增删概率遵循默认的独立同均匀分布(或任何其他分布)，用来反映图的语义对边连接模式的改变具有一定的鲁棒性。
- 属性掩盖（Attribute masking）：随机删除部分节点的属性信息，迫使模型根据节点的上下文信息（邻接信息）来重构被掩盖掉的节点属性。基于的假设是缺少部分节点属性不会对模型的预测造成太大影响。
- 子图（Subgraph）：使用随机游走从图中采样子图。基本的假设是图的语义信息能够在图的局部结构中保留。

#### Model

![image-20201222215513835](https://raw.githubusercontent.com/jjzhou012/image/master/blogImg20201222215513.png)

提出了一个图对比框架GraphCL。在图对比学习中，通过潜在空间中的对比损失来最大化同一图的两个增强视图之间的一致性来执行预训练。整个框架由4部分组成：

- Graph data augmentation. 

  对给定图$\mathcal{G}$使用数据增强生成两个视图作为正样本对，其中$$
  \hat{\mathcal{G}}_{i} \sim q_{i}(\cdot \mid \mathcal{G}), \hat{\mathcal{G}}_{j} \sim q_{j}(\cdot \mid \mathcal{G})$$。

- GNN-based encoder.

  基于GNN的自编码器$$f(\cdot)$$用于提取图级别的向量表示$$\boldsymbol{h}_{i}, \boldsymbol{h}_{j}$$。

- Projection head.

  名为投影头的非线性变换$$g(\cdot)$$将增广表示映射到另一个计算对比损失的潜在空间。

- Contrastive loss function.

  对比损失函数$$\mathcal{L}(\cdot)$$用于强制最大化正样本对$$z_i,z_j$$之间的一致性。

#### Conclusion

- 数据扩充对图对比学习至关重要（引入图数据扩充很容易带来性能提升）
- 组合不同的扩充方式会带来更多的性能收益
- 对于不同类型的数据集来说，最优的DA组合也是不同的（dataset-specific）
  - 边扰动 有益于社交网络，但是不利于生化分子网络。
  - 属性掩盖 在更密集的图上有更好的表现。
  - 节点删除和子图，尤其是后者，在研究的数据集中似乎是普遍有益的。
- 过于简单的对比任务对性能的表现无济于事。

------

### Paper 3

- Paper: **Deep Graph Contrastive Representation Learning** (ICML2020 workshop)
- Code: https://github.com/CRIPAC-DIG/GRACE

#### DA

- **Removing edges (RE):** 在原图上随机移除部分的边。处理邻接矩阵A：在有边的地方放置伯努利分布的数据，在没有边的地方置零。
- **Masking node features (MF)：**在节点特征中随机地用零掩盖一部分维数。

#### Model

![image-20210106193227133](https://raw.githubusercontent.com/jjzhou012/image/master/blogImg20210106193227.png)

- 通过对原图进行随机腐败来产生两个图视图；
- 采用了一个对比目标，使两个不同视图中每个节点的嵌入编码一致，并能与其他节点的嵌入区分开来。
- ![image-20210106133857169](https://raw.githubusercontent.com/jjzhou012/image/master/blogImg20210106133857.png)



------

### Paper 4 (论文3的另一个版本)

- Paper: **Graph Contrastive Learning with Adaptive Augmentations** (arxiv)
- 

#### DA

- 在数据增强中，重要的节点（边、特征）扰动概率小，不重要的节点（边、特征）扰动概率大。

  具体来说，通过随机**删除图中的边**和**屏蔽节点特征**来破坏输入图，并且对于不重要的边或特征的删除或屏蔽概率是倾斜的，即不重要的边或特征的删除或屏蔽概率较高，重要的边或特征的删除或屏蔽概率较低。

- 通过**节点中心性**来衡量重要性，进一步计算采样概率。

  - 度中心性、特征向量中心性、PageRank中心性

#### Model

![image-20210105154312736](https://raw.githubusercontent.com/jjzhou012/image/master/blogImg20210105154312.png)

- 正样本对：同节点&不同视角
- 负样本对：
  - 不同节点&同视角
  - 不同节点&不同视角
- ![image-20210106133857169](https://raw.githubusercontent.com/jjzhou012/image/master/blogImg20210106133857.png)

#### Conclusion

- DA中自适应的采样分布比均匀分布要好。也就是说考虑节点的重要性是有效果的。
- 该GCA框架在节点分类任务上优于baseline。



------

### Paper 5

- Paper: **Contrastive Multi-View Representation Learning on Graphs**()
- Code:

#### DA

定义不同的diffusion作为multi-view:

- ADJ(自身)
- Personalized PageRank (PPR)
- heat kernel

#### Model

![image-20210106192133839](https://raw.githubusercontent.com/jjzhou012/image/master/blogImg20210106192133.png)

- 定义不同的diffusion，生成多视角的增强图，然后在增强图上对相同节点进行子采样。
- 对每个视角，GCN编码器生成节点表示；
- 每个视角的节点表示通过readout生成图表示；
- 将一个视图的节点表示与另一个视图的图表示(反之亦然)进行对比，并对它们之间的一致性进行评分；

![image-20210107044855917](https://raw.githubusercontent.com/jjzhou012/image/master/blogImg20210107044855.png)



### Paper 6

- Paper: Contrastive and Generative Graph Convolutional Networks for Graph-based Semi-Supervised Learning

#### DA

利用两类图卷积生成两个视角，从局部和全局捕捉节点特征，生成节点表示。

- local-view

  两层基础的gcn

- global-view

  hierarchical-gcn (HGCN)

#### Model

![image-20210111100018212](https://raw.githubusercontent.com/jjzhou012/image/master/blogImg20210111100018.png)

![image-20210111105007487](https://raw.githubusercontent.com/jjzhou012/image/master/blogImg20210111105007.png)



### Paper 7

- Paper: [**InfoGraph: Unsupervised and Semi-supervised Graph-Level Representation Learning via Mutual Information Maximization**](https://openreview.net/forum?id=r1lfF2NYvH) (ICLR 2020)

- Code: [https://github.com/fanyun-sun/InfoGraph?utm_source=catalyzex.com](https://github.com/fanyun-sun/InfoGraph?utm_source=catalyzex.com)



#### Model

##### **无监督模型**

![image-20210111154209286](https://raw.githubusercontent.com/jjzhou012/image/master/blogImg20210111154209.png)

- 邻域聚合
  $$
  h_{v}^{(k)}=\operatorname{COMBINE}^{(k)}\left(h_{v}^{(k-1)}, \text { AGGREGATE }^{(k)}\left(\left\{\left(h_{v}^{(k-1)}, h_{u}^{(k-1)}, e_{u v}\right): u \in \mathcal{N}(v)\right\}\right)\right)
  $$
  多层特征拼接
  $$
  h_{\phi}^{i}=\operatorname{CONCAT}\left(\left\{h_{i}^{(k)}\right\}_{k=1}^{K}\right)
  $$
  获取图表示
  $$
  H_{\phi}(G)=\operatorname{READOUT}\left(\left\{h_{\phi}^{i}\right\}_{i=1}^{N}\right)
  $$

- 判别器：判断输入（全局图表示&patch）是否来自同一个图
  $$
  \hat{\phi}, \hat{\psi}=\underset{\phi, \psi}{\arg \max } \sum_{G \in \mathbf{G}} \frac{1}{|G|} \sum_{u \in G} I_{\phi, \psi}\left(\vec{h}_{\phi}^{u} ; H_{\phi}(G)\right)
  $$

  $$
  \begin{aligned}
  I_{\phi, \psi}\left(h_{\phi}^{i}(G) ; H_{\phi}(G)\right) &:=\\
  \mathbb{E}_{\mathbb{P}} &\left[-\operatorname{sp}\left(-T_{\phi, \psi}\left(\vec{h}_{\phi}^{i}(x), H_{\phi}(x)\right)\right)\right]-\mathbb{E}_{\mathbb{P} \times \tilde{\mathbb{P}}}\left[\operatorname{sp}\left(T_{\phi, \psi}\left(\vec{h}_{\phi}^{i}\left(x^{\prime}\right), H_{\phi}(x)\right)\right)\right]
  \end{aligned}
  $$

##### **监督模型**

![image-20210112101701961](https://raw.githubusercontent.com/jjzhou012/image/master/blogImg20210112101702.png)

- 设计了两个编码器，有监督的编码器和无监督的编码器

- 优化目标
  $$
  \begin{aligned}
  L_{\text {total }}=\sum_{i=1}^{\left|\mathbb{G}^{L}\right|} L_{\text {supervised }}\left(y_{\phi}\left(G_{i}\right), o_{i}\right) &+\sum_{j=1}^{\left|\mathbb{G}^{L}\right|+\left|\mathbb{G}^{U}\right|} L_{\text {unsupervised }}\left(h_{\varphi}\left(G_{j}\right) ; H_{\varphi}\left(G_{j}\right)\right) \\
  &-\lambda \sum_{j=1}^{\left|\mathbb{G}^{L}\right|+\left|\mathbb{G}^{U}\right|} \frac{1}{\left|G_{j}\right|} \sum_{k=1}^{K} I\left(H_{\phi}^{k}\left(G_{j}\right) ; H_{\varphi}^{k}\left(G_{j}\right) \right).
  \end{aligned}
  $$



### Paper 8

- Paper: **SELF-SUPERVISED GRAPH-LEVEL REPRESENTATION LEARNING WITH LOCAL AND GLOBAL STRUCTURE**
- Code: 



![image-20210112130303346](https://raw.githubusercontent.com/jjzhou012/image/master/blogImg20210112130303.png)

- **Local-instance Structure**: 不同实例间的局部相似性，一对相似的图在嵌入空间中的距离更近；
- **Global-semantic Structure**: 真实世界的数据集通常分布为不同的语义簇，我们将数据集的全局语义结构定义为其语义簇的分布，每个簇用一个原型(即一个代表性簇嵌入)来表示。因为一组图的语义可以以一种分层的方式结构化，我们用层次原型来表示整个数据集。

#### DA

由于数据集中的图分布在高度离散的空间中，难以构造图的相关性。

这里采用**节点/边属性掩盖**来构造相关性图，本质上就是数据增强。

由于屏蔽操作没有改变图结构，被屏蔽节点的属性信息被输入到GNN后，可以被周围的邻居信息部分恢复。

因此，关联图对的嵌入可以在特征空间中保持高度的一致性。

#### Model

![image-20210112162738800](https://raw.githubusercontent.com/jjzhou012/image/master/blogImg20210112162738.png)



